{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":23498,"sourceType":"datasetVersion","datasetId":310},{"sourceId":3594108,"sourceType":"datasetVersion","datasetId":2156255}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Importing libraries\n\nimport pandas as pd \nimport numpy as np\nfrom numpy import float32\nfrom tqdm import tqdm\n\nfrom typing import Optional\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import recall_score, confusion_matrix, precision_score,roc_auc_score,f1_score\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.multiprocessing import set_start_method\n\nimport pytorch_lightning as pl\n\nfrom torch.utils.data import DataLoader, Dataset\nimport os\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:13.187780Z","iopub.execute_input":"2024-11-25T03:49:13.188103Z","iopub.status.idle":"2024-11-25T03:49:19.924951Z","shell.execute_reply.started":"2024-11-25T03:49:13.188072Z","shell.execute_reply":"2024-11-25T03:49:19.924253Z"},"trusted":true},"outputs":[],"execution_count":1},{"cell_type":"code","source":"random_seed = 123\ntorch.manual_seed(random_seed)\n\nBATCH_SIZE=1000\nAVAIL_GPUS = min(1, torch.cuda.device_count())\nNUM_WORKERS=0\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:19.926523Z","iopub.execute_input":"2024-11-25T03:49:19.927005Z","iopub.status.idle":"2024-11-25T03:49:19.960874Z","shell.execute_reply.started":"2024-11-25T03:49:19.926965Z","shell.execute_reply":"2024-11-25T03:49:19.960143Z"},"trusted":true},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda', index=0)"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"#df = pd.read_csv(\"/kaggle/input/credit-card-fraud/card_transdata.csv\")\ndf = pd.read_csv(\"/input/creditcardfraud/creditcard.csv\")\n#df.rename(columns={'fraud':'Class'},inplace=True)\n# df = df.drop(['type','nameDest','nameOrign'],axis=1)\nfrom sklearn.preprocessing import StandardScaler\nMx = df.iloc[:, :-1]  # 所有行，除了最后一列\nnx = df.iloc[:, -1]   # 所有行的最后一列\n\n# 创建 StandardScaler 对象\nscaler = StandardScaler()\n\n# 对特征进行拟合和转换\nMx_scaled = pd.DataFrame(scaler.fit_transform(Mx), columns=Mx.columns)\n\n# 如果你想保留原始的目标变量，可以这样做：\nscaled_data = pd.concat([Mx_scaled, nx], axis=1)\n\n# 现在，scaled_data 就是标准化后的数据集\n# 你可以查看结果\nscaled_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:19.961747Z","iopub.execute_input":"2024-11-25T03:49:19.961967Z","iopub.status.idle":"2024-11-25T03:49:23.240924Z","shell.execute_reply.started":"2024-11-25T03:49:19.961945Z","shell.execute_reply":"2024-11-25T03:49:23.239974Z"},"trusted":true},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"       Time        V1        V2        V3        V4        V5        V6  \\\n0 -1.996583 -0.694242 -0.044075  1.672773  0.973366 -0.245117  0.347068   \n1 -1.996583  0.608496  0.161176  0.109797  0.316523  0.043483 -0.061820   \n2 -1.996562 -0.693500 -0.811578  1.169468  0.268231 -0.364572  1.351454   \n3 -1.996562 -0.493325 -0.112169  1.182516 -0.609727 -0.007469  0.936150   \n4 -1.996541 -0.591330  0.531541  1.021412  0.284655 -0.295015  0.071999   \n\n         V7        V8        V9  ...       V21       V22       V23       V24  \\\n0  0.193679  0.082637  0.331128  ... -0.024923  0.382854 -0.176911  0.110507   \n1 -0.063700  0.071253 -0.232494  ... -0.307377 -0.880077  0.162201 -0.561131   \n2  0.639776  0.207373 -1.378675  ...  0.337632  1.063358  1.456320 -1.138092   \n3  0.192071  0.316018 -1.262503  ... -0.147443  0.007267 -0.304777 -1.941027   \n4  0.479302 -0.226510  0.744326  ... -0.012839  1.100011 -0.220123  0.233250   \n\n        V25       V26       V27       V28    Amount  Class  \n0  0.246585 -0.392170  0.330892 -0.063781  0.244964      0  \n1  0.320694  0.261069 -0.022256  0.044608 -0.342475      0  \n2 -0.628537 -0.288447 -0.137137 -0.181021  1.160686      0  \n3  1.241904 -0.460217  0.155396  0.186189  0.140534      0  \n4 -0.395202  1.041611  0.543620  0.651816 -0.073403      0  \n\n[5 rows x 31 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Time</th>\n      <th>V1</th>\n      <th>V2</th>\n      <th>V3</th>\n      <th>V4</th>\n      <th>V5</th>\n      <th>V6</th>\n      <th>V7</th>\n      <th>V8</th>\n      <th>V9</th>\n      <th>...</th>\n      <th>V21</th>\n      <th>V22</th>\n      <th>V23</th>\n      <th>V24</th>\n      <th>V25</th>\n      <th>V26</th>\n      <th>V27</th>\n      <th>V28</th>\n      <th>Amount</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-1.996583</td>\n      <td>-0.694242</td>\n      <td>-0.044075</td>\n      <td>1.672773</td>\n      <td>0.973366</td>\n      <td>-0.245117</td>\n      <td>0.347068</td>\n      <td>0.193679</td>\n      <td>0.082637</td>\n      <td>0.331128</td>\n      <td>...</td>\n      <td>-0.024923</td>\n      <td>0.382854</td>\n      <td>-0.176911</td>\n      <td>0.110507</td>\n      <td>0.246585</td>\n      <td>-0.392170</td>\n      <td>0.330892</td>\n      <td>-0.063781</td>\n      <td>0.244964</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-1.996583</td>\n      <td>0.608496</td>\n      <td>0.161176</td>\n      <td>0.109797</td>\n      <td>0.316523</td>\n      <td>0.043483</td>\n      <td>-0.061820</td>\n      <td>-0.063700</td>\n      <td>0.071253</td>\n      <td>-0.232494</td>\n      <td>...</td>\n      <td>-0.307377</td>\n      <td>-0.880077</td>\n      <td>0.162201</td>\n      <td>-0.561131</td>\n      <td>0.320694</td>\n      <td>0.261069</td>\n      <td>-0.022256</td>\n      <td>0.044608</td>\n      <td>-0.342475</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-1.996562</td>\n      <td>-0.693500</td>\n      <td>-0.811578</td>\n      <td>1.169468</td>\n      <td>0.268231</td>\n      <td>-0.364572</td>\n      <td>1.351454</td>\n      <td>0.639776</td>\n      <td>0.207373</td>\n      <td>-1.378675</td>\n      <td>...</td>\n      <td>0.337632</td>\n      <td>1.063358</td>\n      <td>1.456320</td>\n      <td>-1.138092</td>\n      <td>-0.628537</td>\n      <td>-0.288447</td>\n      <td>-0.137137</td>\n      <td>-0.181021</td>\n      <td>1.160686</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-1.996562</td>\n      <td>-0.493325</td>\n      <td>-0.112169</td>\n      <td>1.182516</td>\n      <td>-0.609727</td>\n      <td>-0.007469</td>\n      <td>0.936150</td>\n      <td>0.192071</td>\n      <td>0.316018</td>\n      <td>-1.262503</td>\n      <td>...</td>\n      <td>-0.147443</td>\n      <td>0.007267</td>\n      <td>-0.304777</td>\n      <td>-1.941027</td>\n      <td>1.241904</td>\n      <td>-0.460217</td>\n      <td>0.155396</td>\n      <td>0.186189</td>\n      <td>0.140534</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.996541</td>\n      <td>-0.591330</td>\n      <td>0.531541</td>\n      <td>1.021412</td>\n      <td>0.284655</td>\n      <td>-0.295015</td>\n      <td>0.071999</td>\n      <td>0.479302</td>\n      <td>-0.226510</td>\n      <td>0.744326</td>\n      <td>...</td>\n      <td>-0.012839</td>\n      <td>1.100011</td>\n      <td>-0.220123</td>\n      <td>0.233250</td>\n      <td>-0.395202</td>\n      <td>1.041611</td>\n      <td>0.543620</td>\n      <td>0.651816</td>\n      <td>-0.073403</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Creating function to plot confusion metrics for evaluation\ndef plot_cm(labels, predictions, p=0.5):\n    cm = confusion_matrix(labels, predictions)\n    plt.figure(figsize=(5,5))\n    sns.heatmap(cm, annot=True, fmt=\"d\")\n    plt.title('Confusion matrix @{:.2f}'.format(p))\n    plt.ylabel('Actual label')\n    plt.xlabel('Predicted label')","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.243318Z","iopub.execute_input":"2024-11-25T03:49:23.243976Z","iopub.status.idle":"2024-11-25T03:49:23.248312Z","shell.execute_reply.started":"2024-11-25T03:49:23.243941Z","shell.execute_reply":"2024-11-25T03:49:23.247470Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"train, test = train_test_split(df, test_size=0.2, stratify=df['Class'])\ntrain.shape, test.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.249327Z","iopub.execute_input":"2024-11-25T03:49:23.249589Z","iopub.status.idle":"2024-11-25T03:49:23.411775Z","shell.execute_reply.started":"2024-11-25T03:49:23.249565Z","shell.execute_reply":"2024-11-25T03:49:23.410853Z"},"trusted":true},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"((227845, 31), (56962, 31))"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Normalizing the data\ndata_mean = train.iloc[:,:-1].mean()\ndata_std = train.iloc[:,:-1].std()\ntrain_norm = (train.iloc[:,:-1] - data_mean)/data_std\ntest_norm = (test.iloc[:,:-1] - data_mean)/data_std\ntrain_norm['Class'] =  train.iloc[:, -1]\ntest_norm['Class'] =  test.iloc[:, -1]","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.412738Z","iopub.execute_input":"2024-11-25T03:49:23.412970Z","iopub.status.idle":"2024-11-25T03:49:23.586847Z","shell.execute_reply.started":"2024-11-25T03:49:23.412948Z","shell.execute_reply":"2024-11-25T03:49:23.586155Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_norm['Class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.587804Z","iopub.execute_input":"2024-11-25T03:49:23.588068Z","iopub.status.idle":"2024-11-25T03:49:23.601198Z","shell.execute_reply.started":"2024-11-25T03:49:23.588042Z","shell.execute_reply":"2024-11-25T03:49:23.600372Z"},"trusted":true},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"Class\n0    227451\n1       394\nName: count, dtype: int64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# Creating data model to use with the pytorch Lightning package\nclass CreditCardDataFinal(Dataset):\n    def __init__(self, data: pd.DataFrame):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        label = torch.tensor(self.data[index][-1], dtype=torch.float32)\n        row = torch.tensor(self.data[index][:-1], dtype=torch.float32)\n        return row, label\n    \nclass CreditCardDataModel(pl.LightningDataModule):\n    def __init__(self, data: pd.DataFrame, batch_size=BATCH_SIZE, num_workers=0):\n        super().__init__()\n        self.data = data\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n    \n    def setup(self, stage: Optional[str] = None):\n        train_df, test_df = train_test_split(self.data, random_state=123, test_size=0.2, stratify=self.data['Class'])\n        self.train_df = torch.tensor(train_norm.to_numpy(float32), dtype=torch.float32)\n        self.test_df = torch.tensor(test_norm.to_numpy(float32), dtype=torch.float32)\n\n    def train_dataloader(self):\n        return DataLoader(dataset=CreditCardDataFinal(self.train_df), batch_size=self.batch_size, num_workers=self.num_workers)\n    \n    def test_dataloader(self):\n        return DataLoader(dataset=CreditCardDataFinal(self.test_df), batch_size=self.batch_size, num_workers=self.num_workers)\n    ","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.602185Z","iopub.execute_input":"2024-11-25T03:49:23.602458Z","iopub.status.idle":"2024-11-25T03:49:23.612966Z","shell.execute_reply.started":"2024-11-25T03:49:23.602402Z","shell.execute_reply":"2024-11-25T03:49:23.612183Z"},"trusted":true},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# Building the main neural network to predict if the data is fraud or not. \nclass ModelCreditCard(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        self.sequential = nn.Sequential(\n            nn.Linear(input_size, 100),\n            nn.LeakyReLU(0.1),\n            nn.Linear(100, 50),\n            nn.LeakyReLU(0.1),\n            nn.Linear(50, 25),\n            nn.LeakyReLU(0.1),\n            nn.Linear(25, 1)\n        )\n    \n    def forward(self, x):\n        tensor = torch.sigmoid(self.sequential(x))\n        return tensor\n    \n\nclass ModelTraining(pl.LightningModule):\n    def __init__(self, model, lr=1e-3):\n        super().__init__()\n        self.save_hyperparameters()\n        self.model = model\n        \n    \n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        x = torch.tensor(x, dtype=torch.float32)\n        y = torch.tensor(y, dtype=torch.float32)\n        y_hat = self.model(x)\n        y = y.unsqueeze(1)\n        loss = self.binary_loss(y_hat, y)\n        return {\"loss\":loss}\n    \n    def binary_loss(self, y_hat,y):\n        return F.binary_cross_entropy(y_hat, y)\n    \n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        opt_g = torch.optim.Adam(self.model.parameters(), lr )\n        return [opt_g], []","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.613883Z","iopub.execute_input":"2024-11-25T03:49:23.614117Z","iopub.status.idle":"2024-11-25T03:49:23.624865Z","shell.execute_reply.started":"2024-11-25T03:49:23.614094Z","shell.execute_reply":"2024-11-25T03:49:23.624091Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"trainer = pl.Trainer(max_epochs=10, accelerator='cuda', devices=1)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.627508Z","iopub.execute_input":"2024-11-25T03:49:23.627808Z","iopub.status.idle":"2024-11-25T03:49:23.704239Z","shell.execute_reply.started":"2024-11-25T03:49:23.627782Z","shell.execute_reply":"2024-11-25T03:49:23.703442Z"},"trusted":true},"outputs":[],"execution_count":10},{"cell_type":"code","source":"model_card = ModelCreditCard(30)\nmodel = ModelTraining(model_card)\n\ndm = CreditCardDataModel(train_norm)\n\ntrainer = pl.Trainer(max_epochs=5, accelerator='gpu', devices=1)\ntrainer.fit(model, dm)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:49:23.705104Z","iopub.execute_input":"2024-11-25T03:49:23.705341Z","iopub.status.idle":"2024-11-25T03:50:13.665650Z","shell.execute_reply.started":"2024-11-25T03:49:23.705317Z","shell.execute_reply":"2024-11-25T03:50:13.664818Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a899093a28b4442bb3766c74fa449aa3"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/2301993358.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  label = torch.tensor(self.data[index][-1], dtype=torch.float32)\n/tmp/ipykernel_36/2301993358.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  row = torch.tensor(self.data[index][:-1], dtype=torch.float32)\n/tmp/ipykernel_36/2487196158.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  x = torch.tensor(x, dtype=torch.float32)\n/tmp/ipykernel_36/2487196158.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y = torch.tensor(y, dtype=torch.float32)\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"test_pred = torch.tensor(test_norm.drop([\"Class\"], axis=1).to_numpy()).float()\ntest_true =  test_norm['Class'].to_numpy()\ntest_true = torch.tensor(test_true).unsqueeze(1).float()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:13.666854Z","iopub.execute_input":"2024-11-25T03:50:13.667978Z","iopub.status.idle":"2024-11-25T03:50:13.685589Z","shell.execute_reply.started":"2024-11-25T03:50:13.667937Z","shell.execute_reply":"2024-11-25T03:50:13.684613Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"test_output_real = model_card.forward(test_pred)\ntest_pred_real = [1 if i > 0.5 else 0 for i in test_output_real]\nrecall_score(test_true, test_pred_real)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:13.686843Z","iopub.execute_input":"2024-11-25T03:50:13.687253Z","iopub.status.idle":"2024-11-25T03:50:14.334208Z","shell.execute_reply.started":"2024-11-25T03:50:13.687154Z","shell.execute_reply":"2024-11-25T03:50:14.333338Z"},"trusted":true},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"0.8469387755102041"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"class CreditCardData(Dataset):\n    def __init__(self, data: pd.DataFrame):\n        self.data = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        row = torch.tensor(self.data.iloc[index].values).float()\n        return row","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.573000Z","iopub.execute_input":"2024-11-25T03:50:15.573258Z","iopub.status.idle":"2024-11-25T03:50:15.578070Z","shell.execute_reply.started":"2024-11-25T03:50:15.573232Z","shell.execute_reply":"2024-11-25T03:50:15.577226Z"},"trusted":true},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    def __init__(self, data: pd.DataFrame, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS):\n        super().__init__()\n        self.data = data\n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.data_mean = None\n        self.data_std = None\n        \n    def prepare_data(self):\n        pass\n    \n    def setup(self, stage: Optional[str] = None):\n        train_df, test_df = train_test_split(self.data, random_state=123, test_size=0.2)\n        self.data_mean = train_df.mean()\n        self.data_std = train_df.std()\n        train_norm = (train_df - self.data_mean) / self.data_std\n        test_norm = (test_df - self.data_mean) / self.data_std\n        self.train_df = train_norm\n        self.test_df = test_norm\n    \n    def train_dataloader(self):\n        return DataLoader(dataset=CreditCardData(self.train_df), batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)\n    \n    def valid_dataloader(self):\n        return DataLoader(CreditCardData(self.val_df), batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)\n    \n    def test_dataloader(self):\n        return DataLoader(CreditCardData(self.test_df), batch_size=self.batch_size, num_workers=self.num_workers, pin_memory=True)\n        ","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.578976Z","iopub.execute_input":"2024-11-25T03:50:15.579183Z","iopub.status.idle":"2024-11-25T03:50:15.589387Z","shell.execute_reply.started":"2024-11-25T03:50:15.579163Z","shell.execute_reply":"2024-11-25T03:50:15.588734Z"},"trusted":true},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class GatedSelfAttention(nn.Module):\n    def __init__(self, input_dim):\n        super(GatedSelfAttention, self).__init__()\n        self.query = nn.Linear(input_dim, input_dim)\n        self.key = nn.Linear(input_dim, input_dim)\n        self.value = nn.Linear(input_dim, input_dim)\n        self.gate = nn.Linear(input_dim, input_dim)  # 新增的门控层\n\n    def forward(self, x):\n        Q = self.query(x)\n        K = self.key(x)\n        V = self.value(x)\n        G = torch.sigmoid(self.gate(x))  # 计算门控信号，并通过Sigmoid激活\n        \n        # 计算注意力权重\n        attention_scores = torch.bmm(Q, K.transpose(1, 2)) / (x.size(-1) ** 0.5)\n        attention_weights = F.softmax(attention_scores, dim=-1)\n        \n        # 应用门控机制到值向量上\n        gated_V = V * G  # 逐元素乘法\n        \n        # 应用注意力权重到门控后的值向量\n        attention_output = torch.bmm(attention_weights, gated_V)\n        \n        return attention_output","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.590382Z","iopub.execute_input":"2024-11-25T03:50:15.590922Z","iopub.status.idle":"2024-11-25T03:50:15.606153Z","shell.execute_reply.started":"2024-11-25T03:50:15.590884Z","shell.execute_reply":"2024-11-25T03:50:15.605377Z"},"trusted":true},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class Discriminator(nn.Module):\n    def __init__(self, input_dim=30):\n        super(Discriminator, self).__init__()\n\n        self.conv_layers = nn.Sequential(\n            nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2),\n            nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.LeakyReLU(0.2)\n        )\n\n        self.attention = GatedSelfAttention(64)  # 使用新的门控自注意力模块\n\n        self.fc_layers = nn.Sequential(\n            nn.Linear(64 * input_dim, 128),\n            nn.LeakyReLU(0.2),\n            nn.Linear(128, 64),\n            nn.LeakyReLU(0.2),\n            nn.Linear(64, 1)\n        )\n\n    def forward(self, x):\n        x = x.unsqueeze(1)\n        x = self.conv_layers(x)\n        x = x.transpose(1, 2)\n        x = self.attention(x)\n        x = x.view(x.size(0), -1)\n        x = self.fc_layers(x)\n        return torch.sigmoid(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-25T03:50:15.606964Z","iopub.execute_input":"2024-11-25T03:50:15.607213Z","iopub.status.idle":"2024-11-25T03:50:15.621993Z","shell.execute_reply.started":"2024-11-25T03:50:15.607190Z","shell.execute_reply":"2024-11-25T03:50:15.621232Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#classic generator\nclass Generator(nn.Module):\n    def __init__(self, latent_dim, output_dim):\n        super().__init__()\n        self.latent_dim = latent_dim\n        self.output_dim = output_dim\n        \n        self.model = nn.Sequential(\n            #nn.Linear(latent_dim, output_dim)\n            nn.Linear(latent_dim, 100),\n            nn.LeakyReLU(0.2),\n            nn.Linear(100, 100),\n            nn.LeakyReLU(0.2),\n            nn.Linear(100, output_dim)\n        )\n\n    def forward(self, z):\n        return self.model(z)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.622821Z","iopub.execute_input":"2024-11-25T03:50:15.623058Z","iopub.status.idle":"2024-11-25T03:50:15.632523Z","shell.execute_reply.started":"2024-11-25T03:50:15.623034Z","shell.execute_reply":"2024-11-25T03:50:15.631682Z"},"trusted":true},"outputs":[],"execution_count":20},{"cell_type":"code","source":"class GAN(pl.LightningModule):\n    def __init__(self, latent_dim=100, lr=0.002):\n        super().__init__()\n        self.save_hyperparameters()\n        \n        self.generator = Generator(latent_dim=self.hparams.latent_dim,output_dim=30)  # 假设输出维度为28)\n        self.discriminator = Discriminator()\n        \n        self.validation_z = torch.randn(6, self.hparams.latent_dim).to(self.device)\n\n        self.automatic_optimization = False  # Disable automatic optimization\n        \n    def setup(self, stage):\n        # 获取数据模块\n        data_module = self.trainer.datamodule\n        \n        # 获取数据统计信息\n        self.data_mean = torch.tensor(data_module.data_mean.values, dtype=torch.float32)\n        self.data_std = torch.tensor(data_module.data_std.values, dtype=torch.float32)\n\n    def forward(self, z):\n        # 生成标准化的数据\n        x_normalized = self.generator(z)\n        # 使用数据的均值和方差进行反标准化\n        #x = x_normalized * self.data_std + self.data_mean\n        x = x_normalized\n        return x\n    \n    def adversarial_loss(self, y_hat, y):\n        return F.binary_cross_entropy(y_hat, y)\n    \n    def training_step(self, batch, batch_idx):\n        real_data = batch #.to(self.device)\n        z = torch.randn(real_data.size(0), self.hparams.latent_dim).to(self.device)\n        \n        # Access optimizers manually\n        opt_g, opt_d = self.optimizers()\n        \n        # Train Complementary GAN:\n        \n        # Train CCFD-generator: max log(D(G(z)))\n        fake_data = self.generator(z)\n        y_hat_fake = self.discriminator(fake_data)\n        g_loss = self.adversarial_loss(y_hat_fake, torch.ones_like(y_hat_fake))\n        \n        opt_g.zero_grad()\n        self.manual_backward(g_loss)\n        opt_g.step()\n        \n        # Train CCFD-discriminator: max log(D(x)) + log(1- D(G(z)))\n        y_hat_real = self.discriminator(real_data)\n        y_real = torch.ones(real_data.size(0), 1).to(self.device)\n        real_loss = self.adversarial_loss(y_hat_real, y_real)\n        \n        y_hat_fake = self.discriminator(fake_data.detach())\n        y_fake = torch.zeros(real_data.size(0), 1).to(self.device)\n        fake_loss = self.adversarial_loss(y_hat_fake, y_fake)\n        \n        d_loss = (real_loss + fake_loss) / 2\n        \n        opt_d.zero_grad()\n        self.manual_backward(d_loss)\n        opt_d.step()\n        \n        self.log(\"g_loss\", g_loss, prog_bar=True, logger=True)\n        self.log(\"d_loss\", d_loss, prog_bar=True, logger=True)\n        \n    def configure_optimizers(self):\n        lr = self.hparams.lr\n        opt_g = torch.optim.Adam(self.generator.parameters(), lr)\n        opt_d = torch.optim.Adam(self.discriminator.parameters(), lr)\n        return [opt_g, opt_d]","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.633742Z","iopub.execute_input":"2024-11-25T03:50:15.633984Z","iopub.status.idle":"2024-11-25T03:50:15.650312Z","shell.execute_reply.started":"2024-11-25T03:50:15.633961Z","shell.execute_reply":"2024-11-25T03:50:15.649645Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"only_pos = train_norm[train_norm['Class'] == 1 ].copy()\nonly_pos = only_pos.drop(['Class'], axis=1)\nonly_pos.shape","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.651264Z","iopub.execute_input":"2024-11-25T03:50:15.651543Z","iopub.status.idle":"2024-11-25T03:50:15.669112Z","shell.execute_reply.started":"2024-11-25T03:50:15.651519Z","shell.execute_reply":"2024-11-25T03:50:15.668260Z"},"trusted":true},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"(394, 30)"},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"model = GAN()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.670113Z","iopub.execute_input":"2024-11-25T03:50:15.670353Z","iopub.status.idle":"2024-11-25T03:50:15.685081Z","shell.execute_reply.started":"2024-11-25T03:50:15.670330Z","shell.execute_reply":"2024-11-25T03:50:15.684373Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"dm = DataModule(only_pos)\ntrainer = pl.Trainer(max_epochs=500)\ntrainer.fit(model, dm)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:15.686003Z","iopub.execute_input":"2024-11-25T03:50:15.686259Z","iopub.status.idle":"2024-11-25T03:50:48.759880Z","shell.execute_reply.started":"2024-11-25T03:50:15.686235Z","shell.execute_reply":"2024-11-25T03:50:48.759238Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e159f1d4897847169e0e37e830be09f9"}},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"z = torch.randn(227451,100)\n#227451 730078\noutput = model(z)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:48.760950Z","iopub.execute_input":"2024-11-25T03:50:48.761570Z","iopub.status.idle":"2024-11-25T03:50:49.229649Z","shell.execute_reply.started":"2024-11-25T03:50:48.761533Z","shell.execute_reply":"2024-11-25T03:50:49.228593Z"},"trusted":true},"outputs":[],"execution_count":25},{"cell_type":"markdown","source":"z = torch.randn(10000,100,16)\nt = torch.randint(0, model.hparams.timesteps, (100, 1), dtype=torch.float, device=model.device)\noutput = model(z, t)","metadata":{}},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.230950Z","iopub.execute_input":"2024-11-25T03:50:49.231266Z","iopub.status.idle":"2024-11-25T03:50:49.253610Z","shell.execute_reply.started":"2024-11-25T03:50:49.231235Z","shell.execute_reply":"2024-11-25T03:50:49.252676Z"},"trusted":true},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.6416, -1.9761, -1.5401,  ..., -0.6735,  3.5284,  0.8151],\n        [-0.7106,  1.4402, -3.0575,  ..., -0.6843,  3.1969,  0.7707],\n        [-3.0817, -6.2356,  1.6204,  ...,  0.9288,  0.6119,  2.9910],\n        ...,\n        [-0.0269, -0.1122, -0.3418,  ..., -0.1704, -0.2492, -0.5327],\n        [-0.5119, -1.6599,  0.1305,  ...,  1.0293, -0.6446,  0.9336],\n        [-3.4466, -1.5024, -2.0621,  ..., -0.6449,  4.8904,  1.8447]],\n       grad_fn=<AddmmBackward0>)"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"only_pos_df =  pd.DataFrame(output.detach().numpy())\nonly_pos_df","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.254782Z","iopub.execute_input":"2024-11-25T03:50:49.255439Z","iopub.status.idle":"2024-11-25T03:50:49.318077Z","shell.execute_reply.started":"2024-11-25T03:50:49.255375Z","shell.execute_reply":"2024-11-25T03:50:49.317167Z"},"trusted":true},"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"              0         1         2         3         4         5         6   \\\n0      -2.641560 -1.976067 -1.540138 -1.383987  0.728703  0.777461  1.241864   \n1      -0.710555  1.440228 -3.057508  0.273666 -0.497588  2.195228  0.454073   \n2      -3.081708 -6.235551  1.620369 -4.568712  4.286985 -2.173527  4.022481   \n3       0.015660  0.216741 -0.464185 -0.014711 -0.122397  0.250846 -0.192409   \n4      -0.391105  1.311822 -2.225316  0.588304 -1.078543  1.950081 -0.359852   \n...          ...       ...       ...       ...       ...       ...       ...   \n227446 -0.444597  0.549325 -1.709663  0.074521 -0.520293  1.257302 -0.153161   \n227447 -0.281702  0.088270 -0.528383 -0.139688 -0.182242  0.366270 -0.214762   \n227448 -0.026909 -0.112187 -0.341779 -0.193211 -0.021847  0.321943 -0.107296   \n227449 -0.511930 -1.659882  0.130521 -1.391057  1.238460 -0.657452  0.958512   \n227450 -3.446633 -1.502354 -2.062054 -0.816638  0.149592  1.777593  1.146224   \n\n              7         8         9   ...        20        21        22  \\\n0      -0.927886  0.425667  0.096496  ...  2.996011 -0.552803  0.550084   \n1       0.292704  0.505700  1.388119  ...  0.613176  0.276237 -0.022336   \n2       0.794505  1.958356 -2.818753  ...  2.576996 -0.465570  0.601161   \n3       0.044336 -0.261046  0.094011  ...  0.051491  0.045075 -0.331449   \n4      -0.044559 -0.132108  1.559947  ...  0.661241 -0.084365 -0.296366   \n...          ...       ...       ...  ...       ...       ...       ...   \n227446 -0.140964 -0.147480  1.248211  ...  0.676547 -0.002290 -0.428365   \n227447 -0.070377 -0.393761  0.569488  ...  0.435953 -0.007772 -0.416317   \n227448 -0.257433 -0.230307 -0.127958  ...  0.493512 -0.450669 -0.457724   \n227449  0.576717  0.137283 -0.435263  ...  0.262065  0.159768 -0.616801   \n227450 -0.912709  0.327280  0.620906  ...  3.370369 -0.124653  0.814027   \n\n              23        24        25        26        27        28        29  \n0       0.954487 -3.928111 -0.330122 -1.965147 -0.673526  3.528360  0.815128  \n1       0.177680 -3.022206  0.432996 -0.251197 -0.684285  3.196902  0.770665  \n2       0.289839 -2.216034 -0.048738 -3.434725  0.928773  0.611906  2.991007  \n3      -0.210471  0.099484  0.294869  0.169326 -0.129763 -0.127137 -0.249410  \n4       1.098889 -2.159106  0.501519 -0.036584 -0.135677  2.197541  0.459307  \n...          ...       ...       ...       ...       ...       ...       ...  \n227446  1.066271 -1.755755  0.401285 -0.197728  0.115720  1.584828  0.614690  \n227447  0.470014 -0.660775  0.192486  0.024400  0.087208  0.619964  0.275251  \n227448  0.100568  0.395795  0.549172  0.061587 -0.170438 -0.249233 -0.532724  \n227449  0.557368 -0.232300  0.565052 -0.730139  1.029283 -0.644564  0.933621  \n227450  1.001887 -5.896956 -1.405307 -2.565929 -0.644857  4.890408  1.844698  \n\n[227451 rows x 30 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>6</th>\n      <th>7</th>\n      <th>8</th>\n      <th>9</th>\n      <th>...</th>\n      <th>20</th>\n      <th>21</th>\n      <th>22</th>\n      <th>23</th>\n      <th>24</th>\n      <th>25</th>\n      <th>26</th>\n      <th>27</th>\n      <th>28</th>\n      <th>29</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>-2.641560</td>\n      <td>-1.976067</td>\n      <td>-1.540138</td>\n      <td>-1.383987</td>\n      <td>0.728703</td>\n      <td>0.777461</td>\n      <td>1.241864</td>\n      <td>-0.927886</td>\n      <td>0.425667</td>\n      <td>0.096496</td>\n      <td>...</td>\n      <td>2.996011</td>\n      <td>-0.552803</td>\n      <td>0.550084</td>\n      <td>0.954487</td>\n      <td>-3.928111</td>\n      <td>-0.330122</td>\n      <td>-1.965147</td>\n      <td>-0.673526</td>\n      <td>3.528360</td>\n      <td>0.815128</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.710555</td>\n      <td>1.440228</td>\n      <td>-3.057508</td>\n      <td>0.273666</td>\n      <td>-0.497588</td>\n      <td>2.195228</td>\n      <td>0.454073</td>\n      <td>0.292704</td>\n      <td>0.505700</td>\n      <td>1.388119</td>\n      <td>...</td>\n      <td>0.613176</td>\n      <td>0.276237</td>\n      <td>-0.022336</td>\n      <td>0.177680</td>\n      <td>-3.022206</td>\n      <td>0.432996</td>\n      <td>-0.251197</td>\n      <td>-0.684285</td>\n      <td>3.196902</td>\n      <td>0.770665</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-3.081708</td>\n      <td>-6.235551</td>\n      <td>1.620369</td>\n      <td>-4.568712</td>\n      <td>4.286985</td>\n      <td>-2.173527</td>\n      <td>4.022481</td>\n      <td>0.794505</td>\n      <td>1.958356</td>\n      <td>-2.818753</td>\n      <td>...</td>\n      <td>2.576996</td>\n      <td>-0.465570</td>\n      <td>0.601161</td>\n      <td>0.289839</td>\n      <td>-2.216034</td>\n      <td>-0.048738</td>\n      <td>-3.434725</td>\n      <td>0.928773</td>\n      <td>0.611906</td>\n      <td>2.991007</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.015660</td>\n      <td>0.216741</td>\n      <td>-0.464185</td>\n      <td>-0.014711</td>\n      <td>-0.122397</td>\n      <td>0.250846</td>\n      <td>-0.192409</td>\n      <td>0.044336</td>\n      <td>-0.261046</td>\n      <td>0.094011</td>\n      <td>...</td>\n      <td>0.051491</td>\n      <td>0.045075</td>\n      <td>-0.331449</td>\n      <td>-0.210471</td>\n      <td>0.099484</td>\n      <td>0.294869</td>\n      <td>0.169326</td>\n      <td>-0.129763</td>\n      <td>-0.127137</td>\n      <td>-0.249410</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.391105</td>\n      <td>1.311822</td>\n      <td>-2.225316</td>\n      <td>0.588304</td>\n      <td>-1.078543</td>\n      <td>1.950081</td>\n      <td>-0.359852</td>\n      <td>-0.044559</td>\n      <td>-0.132108</td>\n      <td>1.559947</td>\n      <td>...</td>\n      <td>0.661241</td>\n      <td>-0.084365</td>\n      <td>-0.296366</td>\n      <td>1.098889</td>\n      <td>-2.159106</td>\n      <td>0.501519</td>\n      <td>-0.036584</td>\n      <td>-0.135677</td>\n      <td>2.197541</td>\n      <td>0.459307</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>227446</th>\n      <td>-0.444597</td>\n      <td>0.549325</td>\n      <td>-1.709663</td>\n      <td>0.074521</td>\n      <td>-0.520293</td>\n      <td>1.257302</td>\n      <td>-0.153161</td>\n      <td>-0.140964</td>\n      <td>-0.147480</td>\n      <td>1.248211</td>\n      <td>...</td>\n      <td>0.676547</td>\n      <td>-0.002290</td>\n      <td>-0.428365</td>\n      <td>1.066271</td>\n      <td>-1.755755</td>\n      <td>0.401285</td>\n      <td>-0.197728</td>\n      <td>0.115720</td>\n      <td>1.584828</td>\n      <td>0.614690</td>\n    </tr>\n    <tr>\n      <th>227447</th>\n      <td>-0.281702</td>\n      <td>0.088270</td>\n      <td>-0.528383</td>\n      <td>-0.139688</td>\n      <td>-0.182242</td>\n      <td>0.366270</td>\n      <td>-0.214762</td>\n      <td>-0.070377</td>\n      <td>-0.393761</td>\n      <td>0.569488</td>\n      <td>...</td>\n      <td>0.435953</td>\n      <td>-0.007772</td>\n      <td>-0.416317</td>\n      <td>0.470014</td>\n      <td>-0.660775</td>\n      <td>0.192486</td>\n      <td>0.024400</td>\n      <td>0.087208</td>\n      <td>0.619964</td>\n      <td>0.275251</td>\n    </tr>\n    <tr>\n      <th>227448</th>\n      <td>-0.026909</td>\n      <td>-0.112187</td>\n      <td>-0.341779</td>\n      <td>-0.193211</td>\n      <td>-0.021847</td>\n      <td>0.321943</td>\n      <td>-0.107296</td>\n      <td>-0.257433</td>\n      <td>-0.230307</td>\n      <td>-0.127958</td>\n      <td>...</td>\n      <td>0.493512</td>\n      <td>-0.450669</td>\n      <td>-0.457724</td>\n      <td>0.100568</td>\n      <td>0.395795</td>\n      <td>0.549172</td>\n      <td>0.061587</td>\n      <td>-0.170438</td>\n      <td>-0.249233</td>\n      <td>-0.532724</td>\n    </tr>\n    <tr>\n      <th>227449</th>\n      <td>-0.511930</td>\n      <td>-1.659882</td>\n      <td>0.130521</td>\n      <td>-1.391057</td>\n      <td>1.238460</td>\n      <td>-0.657452</td>\n      <td>0.958512</td>\n      <td>0.576717</td>\n      <td>0.137283</td>\n      <td>-0.435263</td>\n      <td>...</td>\n      <td>0.262065</td>\n      <td>0.159768</td>\n      <td>-0.616801</td>\n      <td>0.557368</td>\n      <td>-0.232300</td>\n      <td>0.565052</td>\n      <td>-0.730139</td>\n      <td>1.029283</td>\n      <td>-0.644564</td>\n      <td>0.933621</td>\n    </tr>\n    <tr>\n      <th>227450</th>\n      <td>-3.446633</td>\n      <td>-1.502354</td>\n      <td>-2.062054</td>\n      <td>-0.816638</td>\n      <td>0.149592</td>\n      <td>1.777593</td>\n      <td>1.146224</td>\n      <td>-0.912709</td>\n      <td>0.327280</td>\n      <td>0.620906</td>\n      <td>...</td>\n      <td>3.370369</td>\n      <td>-0.124653</td>\n      <td>0.814027</td>\n      <td>1.001887</td>\n      <td>-5.896956</td>\n      <td>-1.405307</td>\n      <td>-2.565929</td>\n      <td>-0.644857</td>\n      <td>4.890408</td>\n      <td>1.844698</td>\n    </tr>\n  </tbody>\n</table>\n<p>227451 rows × 30 columns</p>\n</div>"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"only_pos_df['Class'] = 1","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.323620Z","iopub.execute_input":"2024-11-25T03:50:49.323922Z","iopub.status.idle":"2024-11-25T03:50:49.329700Z","shell.execute_reply.started":"2024-11-25T03:50:49.323894Z","shell.execute_reply":"2024-11-25T03:50:49.328871Z"},"trusted":true},"outputs":[],"execution_count":28},{"cell_type":"code","source":"only_neg_real_df = train_norm[train_norm['Class'] == 0]","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.330747Z","iopub.execute_input":"2024-11-25T03:50:49.331009Z","iopub.status.idle":"2024-11-25T03:50:49.368712Z","shell.execute_reply.started":"2024-11-25T03:50:49.330984Z","shell.execute_reply":"2024-11-25T03:50:49.367879Z"},"trusted":true},"outputs":[],"execution_count":29},{"cell_type":"code","source":"train_combined_fake_pos_only = only_pos_df\ntrain_combined_fake_pos_only.columns = only_neg_real_df.columns\ntrain_combined_fake_pos_only = pd.concat([only_pos_df, only_neg_real_df], ignore_index=True)\ntrain_combined_fake_pos_only = train_combined_fake_pos_only.sample(frac=1) # Shuffle the dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.369773Z","iopub.execute_input":"2024-11-25T03:50:49.370066Z","iopub.status.idle":"2024-11-25T03:50:49.563221Z","shell.execute_reply.started":"2024-11-25T03:50:49.370037Z","shell.execute_reply":"2024-11-25T03:50:49.562534Z"},"trusted":true},"outputs":[],"execution_count":30},{"cell_type":"code","source":"train_combined_fake_pos_only['Class'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.564210Z","iopub.execute_input":"2024-11-25T03:50:49.564506Z","iopub.status.idle":"2024-11-25T03:50:49.573422Z","shell.execute_reply.started":"2024-11-25T03:50:49.564481Z","shell.execute_reply":"2024-11-25T03:50:49.572581Z"},"trusted":true},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"Class\n1    227451\n0    227451\nName: count, dtype: int64"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"model_card_with_gan = ModelCreditCard(30)\nmodel_gan = ModelTraining(model_card_with_gan)\ndm_only_gan = CreditCardDataModel(train_combined_fake_pos_only)\ntrainer = pl.Trainer(max_epochs=10, accelerator='cuda', devices=1)\ntrainer.fit(model_gan, dm_only_gan)","metadata":{"execution":{"iopub.status.busy":"2024-11-25T03:50:49.574350Z","iopub.execute_input":"2024-11-25T03:50:49.574599Z","iopub.status.idle":"2024-11-25T03:52:04.834168Z","shell.execute_reply.started":"2024-11-25T03:50:49.574576Z","shell.execute_reply":"2024-11-25T03:52:04.833331Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/pytorch_lightning/utilities/parsing.py:208: Attribute 'model' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['model'])`.\n/opt/conda/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=3` in the `DataLoader` to improve performance.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea50442a25564120b41558f071ccde26"}},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_36/2301993358.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  label = torch.tensor(self.data[index][-1], dtype=torch.float32)\n/tmp/ipykernel_36/2301993358.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  row = torch.tensor(self.data[index][:-1], dtype=torch.float32)\n/tmp/ipykernel_36/2487196158.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  x = torch.tensor(x, dtype=torch.float32)\n/tmp/ipykernel_36/2487196158.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n  y = torch.tensor(y, dtype=torch.float32)\n","output_type":"stream"}],"execution_count":32}]}